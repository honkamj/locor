{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "import equinox\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_test = torch.randn(1, 4, 16, 16, 16)\n",
    "target_data_test = torch.randn(1, 4, 16, 16, 16)\n",
    "source_data_test_numpy = source_data_test.numpy()\n",
    "target_data_test_numpy = target_data_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composable_mapping as cm\n",
    "\n",
    "def local_least_squares_error(\n",
    "    source: cm.GridComposableMapping,\n",
    "    target: cm.GridComposableMapping,\n",
    "    sampler: cm.ISampler,\n",
    "    coordinates: cm.CoordinateSystem,\n",
    "    regularization: int | float | None = None,\n",
    "    eps: int | float = 1e-4,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute the local least squares loss between two images.\n",
    "\n",
    "    Returns:\n",
    "        The local least squares loss and the local weights if `return_weights` is `True`.\n",
    "    \"\"\"\n",
    "    source_sampled = source.sample()\n",
    "    target_sampled = target.sample()\n",
    "    source_image, source_mask = source_sampled.generate(generate_missing_mask=False)\n",
    "    target_image, target_mask = target_sampled.generate(generate_missing_mask=False)\n",
    "    mask = cm.util.combine_optional_masks(source_mask, target_mask)\n",
    "    if mask is not None:\n",
    "        source_image = source_image * mask\n",
    "        target_image = target_image * mask\n",
    "    n_source_features = source_image.size(1)\n",
    "    n_target_features = target_image.size(1)\n",
    "\n",
    "    source_product_indices_1, source_product_indices_2 = torch.triu_indices(\n",
    "        n_source_features, n_source_features, offset=1, device=source.device\n",
    "    )\n",
    "    n_source_products = source_product_indices_1.size(0)\n",
    "    source_indices = torch.arange(n_source_features, device=source.device)\n",
    "\n",
    "    moving_averages = (\n",
    "        cm.samplable_volume(\n",
    "            torch.cat(\n",
    "                (\n",
    "                    source_image[:, source_product_indices_1]\n",
    "                    * source_image[:, source_product_indices_2],\n",
    "                    (source_image[:, :, None] * target_image[:, None, :]).view(\n",
    "                        source_sampled.batch_shape[0], -1, *source_sampled.spatial_shape\n",
    "                    ),\n",
    "                    source_image**2,\n",
    "                    target_image**2,\n",
    "                ),\n",
    "                dim=1,\n",
    "            ),\n",
    "            coordinate_system=source.coordinate_system,\n",
    "            sampler=sampler,\n",
    "        )\n",
    "        .sample_to(coordinates)\n",
    "        .generate_values()\n",
    "    ).moveaxis(1, -1)\n",
    "\n",
    "    (\n",
    "        source_product_avg,\n",
    "        source_target_avg,\n",
    "        source_squared_avg,\n",
    "        target_squared_avg,\n",
    "    ) = moving_averages.split(\n",
    "        [\n",
    "            n_source_products,\n",
    "            n_source_features * n_target_features,\n",
    "            n_source_features,\n",
    "            n_target_features,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    avg_spatial_shape = moving_averages.shape[1:-1]\n",
    "    source_target_avg = source_target_avg.view(\n",
    "        source_sampled.batch_shape[0],\n",
    "        *avg_spatial_shape,\n",
    "        n_source_features,\n",
    "        n_target_features,\n",
    "    )\n",
    "    least_squares_matrix = torch.empty(\n",
    "        source_sampled.batch_shape[0],\n",
    "        *avg_spatial_shape,\n",
    "        n_source_features,\n",
    "        n_source_features,\n",
    "        device=source.device,\n",
    "        dtype=source.dtype,\n",
    "    )\n",
    "    least_squares_matrix[..., source_product_indices_1, source_product_indices_2] = (\n",
    "        source_product_avg\n",
    "    )\n",
    "    least_squares_matrix[..., source_product_indices_2, source_product_indices_1] = (\n",
    "        source_product_avg\n",
    "    )\n",
    "    least_squares_matrix[..., source_indices, source_indices] = source_squared_avg\n",
    "    if regularization is not None:\n",
    "        regularization_diagonal = torch.full(\n",
    "            (n_source_features,), regularization, dtype=source.dtype, device=source.device\n",
    "        )\n",
    "        least_squares_matrix = least_squares_matrix + torch.diag(regularization_diagonal).view(\n",
    "            1, *(1 for _ in avg_spatial_shape), n_source_features, n_source_features\n",
    "        )\n",
    "\n",
    "    weights, _ = torch.linalg.solve_ex(least_squares_matrix, source_target_avg)  # pylint:disable=not-callable\n",
    "\n",
    "    loss = (\n",
    "        (\n",
    "            (\n",
    "                (\n",
    "                    2\n",
    "                    * weights[..., source_product_indices_1, :]\n",
    "                    * weights[..., source_product_indices_2, :]\n",
    "                    * source_product_avg[..., None]\n",
    "                ).sum(dim=-2)\n",
    "                - (2 * weights * source_target_avg).sum(dim=-2)\n",
    "                + (weights**2 * source_squared_avg[..., None]).sum(dim=-2)\n",
    "                + target_squared_avg\n",
    "            )\n",
    "            + eps\n",
    "        ).log()\n",
    "    ).mean(dim=-1)\n",
    "    return loss[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16, 16, 16])\n",
      "-0.4502831697463989\n"
     ]
    }
   ],
   "source": [
    "sampler = cm.CubicSplineSampler()\n",
    "coordinate_system = cm.CoordinateSystem.voxel(\n",
    "    spatial_shape=source_data_test.shape[2:],\n",
    ")\n",
    "source_test = cm.samplable_volume(source_data_test, coordinate_system=coordinate_system)\n",
    "target_test = cm.samplable_volume(target_data_test, coordinate_system=coordinate_system)\n",
    "\n",
    "loss = local_least_squares_error(source_test, target_test, sampler, coordinate_system, regularization=1)\n",
    "print(loss.shape)\n",
    "print(float(loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 16, 16, 16)\n",
      "-0.45028313994407654\n"
     ]
    }
   ],
   "source": [
    "import jaxmorph as jm\n",
    "import locor\n",
    "import locor.local_least_squares_error\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    sampler = jm.CubicSplineSampler()\n",
    "    coordinate_system = jm.CoordinateSystem.voxel(\n",
    "        spatial_shape=source_data_test.shape[2:],\n",
    "    )\n",
    "    source_test = jm.samplable_volume(source_data_test_numpy, coordinate_system=coordinate_system)\n",
    "    target_test = jm.samplable_volume(target_data_test_numpy, coordinate_system=coordinate_system)\n",
    "\n",
    "    loss = locor.local_least_squares_error.local_least_squares_error(source_test, target_test, sampler, coordinate_system, regularization=1)\n",
    "    print(loss.shape)\n",
    "    print(float(loss.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
